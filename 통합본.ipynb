{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92WHLz8346Yf"
      },
      "source": [
        "# **ğŸ  ë¶€ë™ì‚° ì‹¤ê±°ë˜ê°€ ì˜ˆì¸¡**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-DJzJjvO88V"
      },
      "source": [
        "# 1. Library Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-NiCLGs4ZpM"
      },
      "outputs": [],
      "source": [
        "# visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm \n",
        "\n",
        "font_path=\"G:/ë‚´ ë“œë¼ì´ë¸Œ/NanumGothic.ttf\" # í°íŠ¸ì˜ ì›í•˜ëŠ” ì´ë¦„ ì„¤ì •\n",
        "fm.fontManager.addfont(font_path)           # Matplotlibì— í°íŠ¸ ì¶”ê°€\n",
        "plt.rcParams.update({'font.size': 10, 'font.family': 'NanumGothic'}) # í°íŠ¸ ì„¤ì •\n",
        "plt.rcParams['font.family'] = 'NanumGothic'\n",
        "import seaborn as sns\n",
        "\n",
        "# utils\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import warnings;warnings.filterwarnings('ignore')\n",
        "from datetime import datetime\n",
        "\n",
        "# Model\n",
        "#from sklearnex import patch_sklearn\n",
        "#patch_sklearn()\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from lightgbm import plot_importance\n",
        "from lightgbm.sklearn import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn import metrics\n",
        "import lightgbm as lgb\n",
        "\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "# ì¶”ê°€í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬---------------------------------------------------------------------------------------------\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "from math import radians, sin, cos, sqrt, atan2\n",
        "\n",
        "import missingno as msno  # pip install missingno\n",
        "\n",
        "import folium # pip install folium\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "from functools import partial\n",
        "\n",
        "import joblib\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPJvYT0OPAWS"
      },
      "source": [
        "# 2. Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_path='../data'\n",
        "model_path = '../model'\n",
        "submission_path = '../submission'\n",
        "\n",
        "dt_train = pd.read_csv(f\"{data_path}/train.csv\")\n",
        "dt_test = pd.read_csv(f\"{data_path}/test.csv\")\n",
        "\n",
        "# ì™¸ë¶€ë°ì´í„°\n",
        "subway=pd.read_csv(f'{data_path}/origin/subway_origin.csv')\n",
        "bus=pd.read_csv(f'{data_path}/origin/bus_origin.csv')\n",
        "school=pd.read_csv(f'{data_path}/origin/school_origin.csv',encoding='cp949')\n",
        "money = pd.read_csv(f'{data_path}/ì™¸ë¶€ê¸ˆë¦¬.csv')\n",
        "apart_info = pd.read_parquet(f'{data_path}/ì•„íŒŒíŠ¸ì •ë³´.parquet')\n",
        "real_price=pd.read_csv(f'{data_path}/ì‹¤ê±°ë˜ê°€ê²©ì§€ìˆ˜.csv')\n",
        "income = pd.read_csv(f'{data_path}/ê°€êµ¬ì´ì†Œë“.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6tWMND66vT8",
        "outputId": "e0ba702b-6662-4723-c5a1-600d7236e597"
      },
      "outputs": [],
      "source": [
        "print('Train data shape : ', dt_train.shape, '\\nTest data shape : ', dt_test.shape)\n",
        "display(dt_train.head(1))\n",
        "display(dt_test.head(1))      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2-1. train,test ë³‘í•©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_train['is_test'] = 0\n",
        "dt_test['is_test'] = 1\n",
        "\n",
        "dt_full = pd.concat([dt_train, dt_test])   \n",
        "dt_full.columns = [col.replace('(', '').replace(')', '').replace('ã¡','').replace('~','_').replace('-','_').replace(',','').replace('/','').replace('=','_').replace(' ','_') for col in dt_full.columns]\n",
        "dt_full.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì „ì²´ ë°ì´í„° ê²°ì¸¡ì¹˜ í™•ì¸\n",
        "msno.matrix(dt_full,figsize=(18,7), labels=True,fontsize=12)\n",
        "\n",
        "# ì¤‘ë³µ ì œê±° ê²°ì¸¡ì¹˜ í™•ì¸\n",
        "#msno.matrix(dt_full.drop_duplicates(subset=['ì‹œêµ°êµ¬','ì•„íŒŒíŠ¸ëª…']),figsize=(18,7), labels=True,fontsize=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# íŠ¹ì • ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì‹¤ê±°ë˜ê°€ í‰ê·  ë³´ì—¬ì£¼ëŠ” í•¨ìˆ˜ \n",
        "def group_viz(data,col,plot_type):\n",
        "    \"\"\"\n",
        "    data=input_data\n",
        "    col=ì‹œê°í™”í•˜ê³ ì í•˜ëŠ” ì»¬ëŸ¼\n",
        "    plot_type= bar / plot \n",
        "    \"\"\"\n",
        "    tmp = data.groupby(col)['target'].mean().reset_index()\n",
        "    fig=plt.figure(figsize=(10, 6))\n",
        "    \n",
        "    if(plot_type=='bar'):plt.bar(tmp[col], tmp['target'])\n",
        "    else:plt.plot(tmp[col], tmp['target'], marker='o', linestyle='-', color='b')\n",
        "\n",
        "    plt.xlabel(f'{col}ë³„')\n",
        "    plt.ylabel('í‰ê· ')\n",
        "    plt.title(f'{col}ë³„ í‰ê·  ì‹¤ê±°ë˜ê°€')\n",
        "\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3-1. í•„ìš”ì—†ëŠ” ì»¬ëŸ¼ ì •ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# columns='ê³„ì•½ë…„ì›”'\n",
        "# group_viz(dt_full,columns,'bar')\n",
        "# dt_full[columns].unique()\n",
        "# dt_full[columns].info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "drop_cols=[\"í•´ì œì‚¬ìœ ë°œìƒì¼\",\"ë“±ê¸°ì‹ ì²­ì¼ì\",'ì¤‘ê°œì‚¬ì†Œì¬ì§€','k_ë‹¨ì§€ë¶„ë¥˜ì•„íŒŒíŠ¸ì£¼ìƒë³µí•©ë“±ë“±','k_ì „í™”ë²ˆí˜¸', 'k_íŒ©ìŠ¤ë²ˆí˜¸', 'ë‹¨ì§€ì†Œê°œê¸°ì¡´clob','k_ì‚¬ìš©ê²€ì‚¬ì¼_ì‚¬ìš©ìŠ¹ì¸ì¼',\n",
        "           'k_í™ˆí˜ì´ì§€', 'k_ë“±ë¡ì¼ì','k_ìˆ˜ì •ì¼ì', 'ê³ ìš©ë³´í—˜ê´€ë¦¬ë²ˆí˜¸', 'ê²½ë¹„ë¹„ê´€ë¦¬í˜•íƒœ','ì²­ì†Œë¹„ê´€ë¦¬í˜•íƒœ', 'ê¸°íƒ€ì˜ë¬´ì„ëŒ€ì„ì˜_1234', 'ë‹¨ì§€ìŠ¹ì¸ì¼', 'ì‚¬ìš©í—ˆê°€ì—¬ë¶€','ë‹¨ì§€ì‹ ì²­ì¼']\n",
        "dt_full.drop(drop_cols,axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1ì°¨ ì»¬ëŸ¼ ì œê±° í›„ ë‚¨ì€ ì»¬ëŸ¼\n",
        "dt_full.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3-2.ê²½ìœ„ë„ ê²°ì¸¡ê°’ ì²˜ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê¸°ì¡´ ë°ì´í„°ì—ëŠ” (ì¢Œí‘œx,ì¢Œí‘œy)ë¥¼ ë³´ë©´ ëŒ€ë¶€ë¶„ ê²°ì¸¡ì¹˜ ì¸ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŒ.\n",
        "dt_full[['ì¢Œí‘œX','ì¢Œí‘œY']].info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loc=dt_full[['ì‹œêµ°êµ¬','ë²ˆì§€', 'ì•„íŒŒíŠ¸ëª…','ë„ë¡œëª…', 'ì¢Œí‘œX', 'ì¢Œí‘œY','target']]\n",
        "loc_before= loc.drop_duplicates(subset=['ì‹œêµ°êµ¬','ì•„íŒŒíŠ¸ëª…'],keep='first')\n",
        "loc_before.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loc_before['ì„ì‹œì£¼ì†Œ']=loc_before['ì‹œêµ°êµ¬']+\" \"+loc_before['ë²ˆì§€']\n",
        "loc_before.head(3)\n",
        "#loc_before['ì„ì‹œì£¼ì†Œ'].to_csv(\"../data/loc_before.csv\",index=False)\n",
        "loc_after=pd.read_csv(\"../data/loc_after.csv\")\n",
        "loc_after[['ì‹œêµ°êµ¬', 'ë²ˆì§€']] = loc_after['ë„ë¡œëª…'].str.rsplit(n=1, expand=True)\n",
        "loc_after.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loc_before=loc_before.dropna(subset='ì„ì‹œì£¼ì†Œ')\n",
        "loc_before.reset_index(inplace=True,drop=True)\n",
        "loc_after = pd.merge(loc_before, loc_after, left_index=True, right_index=True)\n",
        "loc_after.head(3)\n",
        "loc_after[['ìœ„ë„','ê²½ë„']].info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì§€ì˜¤ ì½”ë”©ì„ í•´ë„ ê²½ìœ„ë„ê°€ ê²°ì¸¡ì¹˜ì¸ ë°ì´í„°ë“¤ì€ ì•„ë˜ 2ê°€ì§€ ë°©ë²•ì„ ì´ìš©í•˜ì—¬ ì±„ì›€\n",
        "# 1. ê°™ì€ ì‹œêµ°êµ¬ ì•„íŒŒíŠ¸ë“¤ì˜ ê²½ìœ„ë„ì˜ í‰ê· \n",
        "# 2. ê°™ì€ ì•„íŒŒíŠ¸ëª… ì•„íŒŒíŠ¸ë“¤ì˜ í‰ê· \n",
        "missing_data = loc_after[loc_after['ìœ„ë„'].isnull()]\n",
        "avg_sgg = loc_after.groupby('ì‹œêµ°êµ¬_x').agg({'ìœ„ë„': 'mean', 'ê²½ë„': 'mean'}).reset_index()\n",
        "for index, row in missing_data.iterrows():\n",
        "    sgg = row['ì‹œêµ°êµ¬_x']\n",
        "    avg_lat = avg_sgg.loc[avg_sgg['ì‹œêµ°êµ¬_x'] == sgg, 'ìœ„ë„'].values[0]\n",
        "    avg_lon = avg_sgg.loc[avg_sgg['ì‹œêµ°êµ¬_x'] == sgg, 'ê²½ë„'].values[0]\n",
        "    loc_after.loc[index, 'ìœ„ë„'] = avg_lat\n",
        "    loc_after.loc[index, 'ê²½ë„'] = avg_lon\n",
        "    \n",
        "missing_data = loc_after[loc_after['ìœ„ë„'].isnull()]\n",
        "avg_apt = loc_after.groupby('ì•„íŒŒíŠ¸ëª…').agg({'ìœ„ë„': 'mean', 'ê²½ë„': 'mean'}).reset_index()\n",
        "for index, row in missing_data.iterrows():\n",
        "    apt = row['ì•„íŒŒíŠ¸ëª…']\n",
        "    avg_lat = avg_apt.loc[avg_apt['ì•„íŒŒíŠ¸ëª…'] == apt, 'ìœ„ë„'].values[0]\n",
        "    avg_lon = avg_apt.loc[avg_apt['ì•„íŒŒíŠ¸ëª…'] == apt, 'ê²½ë„'].values[0]\n",
        "    loc_after.loc[index, 'ìœ„ë„'] = avg_lat\n",
        "    loc_after.loc[index, 'ê²½ë„'] = avg_lon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê¸°ì¡´ ê²½ìœ„ë„ê°€ ê²°ì¸¡ì¹˜ ì¸ê²ƒë“¤ì— í•œí•´ì„œë§Œ ì§€ì˜¤ì½”ë”©ì˜ ê²°ê³¼ê°’ìœ¼ë¡œ ë°”ê¿ˆ\n",
        "# ì§€ì˜¤ì½”ë”©ì˜ ì•„ì£¼ ì•½ê°„ì˜ ì˜¤ì°¨ê°€ ìˆê¸° ë•Œë¬¸.(-> ì˜¤í”ˆìŠ¤íŠ¸ë¦¬íŠ¸ë§µìœ¼ë¡œ í™•ì¸ ê²°ê³¼ ì‹¤ì œ ì˜¤ì°¨ëŠ” ì—†ìŒ)\n",
        "loc_after['ì¢Œí‘œX'] = loc_after['ì¢Œí‘œX'].fillna(loc_after['ê²½ë„'])\n",
        "loc_after['ì¢Œí‘œY'] = loc_after['ì¢Œí‘œY'].fillna(loc_after['ìœ„ë„'])\n",
        "loc_after.drop(['ì„ì‹œì£¼ì†Œ','ë„ë¡œëª…_y','ìœ„ë„','ê²½ë„','ì‹œêµ°êµ¬_y','ë²ˆì§€_y','target','ë„ë¡œëª…_x'],axis=1,inplace=True)\n",
        "loc_after.columns=['ì‹œêµ°êµ¬', 'ë²ˆì§€', 'ì•„íŒŒíŠ¸ëª…', 'ì¢Œí‘œX', 'ì¢Œí‘œY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê²½ìœ„ë„ ê²°ì¸¡ì¹˜ê°€ ì±„ì›Œì§„ ë°ì´í„°\n",
        "#loc_after.to_csv(\"../data/filled_loc.csv\",index=False)\n",
        "#loc_after=pd.read_csv('../data/filled_loc.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3-3. Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë³¸ë²ˆ, ë¶€ë²ˆ ë²”ì£¼í˜•ìœ¼ë¡œ ë³€í™˜\n",
        "\n",
        "dt_full['ë³¸ë²ˆ'] = dt_full['ë³¸ë²ˆ'].astype('str')\n",
        "dt_full['ë¶€ë²ˆ'] = dt_full['ë¶€ë²ˆ'].astype('str')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3-3-1. ê³„ì•½ë…„ë„, ì›”, ì¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê³„ì•½ë…„ë„ë¥¼ ë…„,ì›”ë¡œ ë¶„í• \n",
        "dt_full['ê³„ì•½ë…„ë„'] = dt_full['ê³„ì•½ë…„ì›”'].astype(str).str[:4].astype(int)\n",
        "dt_full['ê³„ì•½ì›”'] = dt_full['ê³„ì•½ë…„ì›”'].astype(str).str[4:].astype(int)\n",
        "dt_full[['ê³„ì•½ë…„ì›”','ê³„ì•½ë…„ë„','ê³„ì•½ì›”']].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê³„ì•½ë…„ì›”ë³„ ì‹¤ê±°ë˜ê°€ ì‹œê°í™”\n",
        "df=dt_full.copy()\n",
        "df['ë‚ ì§œ'] = pd.to_datetime(df['ê³„ì•½ë…„ë„'].astype(str) + '-' + df['ê³„ì•½ì›”'].astype(str))\n",
        "df = df[['ë‚ ì§œ', 'target']]\n",
        "grouped_data = df.groupby('ë‚ ì§œ')['target'].mean().reset_index()\n",
        "plt.figure(figsize=(15, 6))\n",
        "sns.lineplot(x='ë‚ ì§œ', y='target', data=grouped_data)\n",
        "plt.xlabel('ë‚ ì§œ')\n",
        "plt.ylabel('ì‹¤ê±°ë˜ê°€ê²© í‰ê· ')\n",
        "plt.title('í‰ê·  ì‹¤ê±°ë˜ê°€')\n",
        "plt.show()\n",
        "del df;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3-3-2. ì™¸ë¶€ ë°ì´í„° ê²°í•©(ê²½ìœ„ë„ ê¸°ì¤€)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    R = 6371  # ì§€êµ¬ ë°˜ì§€ë¦„ (ë‹¨ìœ„: km)\n",
        "\n",
        "    dlat = radians(lat2 - lat1)\n",
        "    dlon = radians(lon2 - lon1)\n",
        "\n",
        "    a = sin(dlat / 2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2)**2\n",
        "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
        "\n",
        "    distance = R * c\n",
        "    return distance\n",
        "\n",
        "def near_facility(data,u_dist,type,n,target_col):\n",
        "    \"\"\"\n",
        "    í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê¸° ì „ ì°¸ì¡°ì™¸ë¶€ë°ì´í„°ì— ìœ„ë„,ê²½ë„ columnì´ ì¡´ì¬í•´ì•¼í•¨.\n",
        "    ì¸ì ‘ê±°ë¦¬ë¥¼ ì •í•´ì£¼ê³ , ê°œìˆ˜ë¥¼ ë°˜í™˜í• ì§€ ì´ë¦„ì„ ë°˜í™˜í• ì§€ ê²°ì •í•˜ì—¬ u_distì™€ type ì„¤ì •\n",
        "    target_colë„ dataì— ìˆëŠ” ì»¬ëŸ¼ì´ì–´ì•¼ í•¨.\n",
        "    \n",
        "    \n",
        "    data=ì°¸ì¡° ë°ì´í„°(ë²„ìŠ¤,ì§€í•˜ì² ,í•™êµ ë“±)\n",
        "    u_dist=ì¸ì ‘ê±°ë¦¬(ì†Œìˆ˜ë¡œ.)\n",
        "    type=count:ê°œìˆ˜ë°˜í™˜/name:ì´ë¦„ë°˜í™˜\n",
        "    n=ì¸ì ‘ê°œìˆ˜\n",
        "    target_col=ì°¸ì¡° ì»¬ëŸ¼\n",
        "    \"\"\"\n",
        "    origin_data=loc_after.copy()\n",
        "    for i, origin_coord in enumerate(origin_data[['ì¢Œí‘œY', 'ì¢Œí‘œX']].values):\n",
        "        distances = [haversine(origin_coord[0], origin_coord[1], tmp_coord[0], tmp_coord[1]) for tmp_coord in data[['ìœ„ë„', 'ê²½ë„']].values]\n",
        "        # u_dist ê±°ë¦¬ ë‚´ì— ìˆëŠ” ì‹œì„¤ì„ ìµœëŒ€ nê°œ ì°¾ê¸°\n",
        "        \n",
        "        if(type=='name'):\n",
        "            closest_facility= [idx for idx, dist in sorted(enumerate(distances), key=lambda x: x[1]) if dist <= u_dist][:n]\n",
        "            # ê³„ì‚°ëœ ì¸ì ‘ ì‹œì„¤ì„ ì¶”ê°€ \n",
        "            for j, idx in enumerate(closest_facility):\n",
        "                for k in target_col:\n",
        "                    col_name = f'ì¸ì ‘{k}{j+1}'\n",
        "                    origin_data.at[i, col_name] = data.iloc[idx][k]\n",
        "        else:\n",
        "            closest_facility= [idx for idx, dist in sorted(enumerate(distances), key=lambda x: x[1]) if dist <= u_dist]\n",
        "            col_name = f'ì¸ì ‘{target_col[0]}ê°œìˆ˜'\n",
        "            origin_data.at[i, col_name] = len(closest_facility)\n",
        "                \n",
        "    return origin_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3-3-2-1.ì§€í•˜ì² "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "subway.info(),subway.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tmp=near_facility(data=subway,u_dist=0.7,type='name',n=3,target_col=['ì—­ì‚¬ëª…','í˜¸ì„ '])\n",
        "# tmp.head(3)\n",
        "# loc_after[['ì¸ì ‘ì—­ì‚¬ëª…1', 'ì¸ì ‘í˜¸ì„ 1', 'ì¸ì ‘ì—­ì‚¬ëª…2', 'ì¸ì ‘í˜¸ì„ 2','ì¸ì ‘ì—­ì‚¬ëª…3', 'ì¸ì ‘í˜¸ì„ 3']]=tmp[['ì¸ì ‘ì—­ì‚¬ëª…1', 'ì¸ì ‘í˜¸ì„ 1', 'ì¸ì ‘ì—­ì‚¬ëª…2', 'ì¸ì ‘í˜¸ì„ 2','ì¸ì ‘ì—­ì‚¬ëª…3', 'ì¸ì ‘í˜¸ì„ 3']]\n",
        "# loc_after.head(3)\n",
        "\n",
        "tmp=near_facility(data=subway,u_dist=0.8,type='len',n=None,target_col=['ì—­ì‚¬ëª…']) # 800mì¸ì ‘, ê°œìˆ˜ ë°˜í™˜\n",
        "tmp['ì¸ì ‘ì—­ì‚¬ëª…ê°œìˆ˜']=tmp['ì¸ì ‘ì—­ì‚¬ëª…ê°œìˆ˜'].fillna(0)\n",
        "loc_after[['ì¸ì ‘ì—­ì‚¬ëª…ê°œìˆ˜']]=tmp[['ì¸ì ‘ì—­ì‚¬ëª…ê°œìˆ˜']].astype(int)\n",
        "loc_after.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3-3-2-2.í•™êµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://data.seoul.go.kr/dataList/OA-20502/S/1/datasetView.do\n",
        "school=pd.read_csv(\"../data/origin/school_origin.csv\",encoding='cp949')\n",
        "school=school[['í•™êµì¢…ë¥˜ëª…','ì„¤ë¦½êµ¬ë¶„','í•™êµëª…','ë„ë¡œëª…ì£¼ì†Œ','ë„ë¡œëª…ìƒì„¸ì£¼ì†Œ']]\n",
        "school.head(3)\n",
        "#school.to_csv(\"../data/school_before.csv\",index=False)\n",
        "# Naver ì§€ì˜¤ì½”ë”© apië¥¼ ì´ìš©í•´ ì£¼ì†Œ->ê²½ìœ„ë„ ë³€í™˜ \n",
        "school_after=pd.read_csv(\"../data/school_after.csv\") # í›„ì²˜ë¦¬ëœ school\n",
        "school[['ìœ„ë„','ê²½ë„']]=school_after[['ìœ„ë„','ê²½ë„']]\n",
        "school.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tmp=near_facility(data=school,u_dist=0.9,type='name',n=2,target_col=['í•™êµëª…','í•™êµì¢…ë¥˜ëª…'])\n",
        "# loc_after[['ì¸ì ‘í•™êµëª…1', 'ì¸ì ‘í•™êµì¢…ë¥˜ëª…1', 'ì¸ì ‘í•™êµëª…2', 'ì¸ì ‘í•™êµì¢…ë¥˜ëª…2']]=tmp[['ì¸ì ‘í•™êµëª…1', 'ì¸ì ‘í•™êµì¢…ë¥˜ëª…1', 'ì¸ì ‘í•™êµëª…2', 'ì¸ì ‘í•™êµì¢…ë¥˜ëª…2']]\n",
        "# loc_after.head(3)\n",
        "\n",
        "tmp=near_facility(data=school,u_dist=0.8,type='len',n=None,target_col=['í•™êµëª…'])\n",
        "tmp['ì¸ì ‘í•™êµëª…ê°œìˆ˜']=tmp['ì¸ì ‘í•™êµëª…ê°œìˆ˜'].fillna(0)\n",
        "loc_after[['ì¸ì ‘í•™êµëª…ê°œìˆ˜']]=tmp[['ì¸ì ‘í•™êµëª…ê°œìˆ˜']].astype(int)\n",
        "loc_after.head(3)\n",
        "# ì˜ ë¶™ì—¬ì¡ŒëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ ì•„ë˜ ë§í¬ì— í•´ë‹¹ ì•„íŒŒíŠ¸ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì¸ê·¼ì— ë¶™ì—¬ì§„ í•™êµë¥¼ í™•ì¸\n",
        "# https://hogangnono.com/apt/1OKb7/0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3-3-2-3.ë²„ìŠ¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bus.info(),bus.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bus.columns=['ë…¸ë“œ ID', 'ì •ë¥˜ì†Œë²ˆí˜¸', 'ì •ë¥˜ì†Œëª…', 'ê²½ë„', 'ìœ„ë„', 'ì •ë¥˜ì†Œ íƒ€ì…']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp=near_facility(data=bus,u_dist=0.3,type='len',n=None,target_col=['ì •ë¥˜ì†Œëª…'])\n",
        "tmp['ì¸ì ‘ì •ë¥˜ì†Œëª…ê°œìˆ˜']=tmp['ì¸ì ‘ì •ë¥˜ì†Œëª…ê°œìˆ˜'].fillna(0)\n",
        "loc_after[['ì¸ì ‘ì •ë¥˜ì†Œëª…ê°œìˆ˜']]=tmp[['ì¸ì ‘ì •ë¥˜ì†Œëª…ê°œìˆ˜']].astype(int)\n",
        "loc_after.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full.drop(['ì¢Œí‘œX','ì¢Œí‘œY'],axis=1,inplace=True)\n",
        "dt_full= pd.merge(dt_full, loc_after, on=['ì‹œêµ°êµ¬', 'ë²ˆì§€','ì•„íŒŒíŠ¸ëª…'], how='left')\n",
        "dt_full.columns,dt_full.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full_bak=dt_full.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3-3-2-4. ê¸ˆë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "money.drop(columns=['í†µê³„í‘œ', 'ë‹¨ìœ„', 'ë³€í™˜'], inplace=True)\n",
        "\n",
        "money.columns = [''.join(x) for x in money.columns.str.split('/')]\n",
        "\n",
        "money = pd.melt(money, id_vars=['ê³„ì •í•­ëª©'], var_name='ë…„ì›”', value_name='ê¸ˆë¦¬')\n",
        "money['ë…„ì›”'] = money['ë…„ì›”'].astype(np.int32)\n",
        "\n",
        "money = money.pivot(index='ë…„ì›”', columns='ê³„ì •í•­ëª©', values='ê¸ˆë¦¬').reset_index()\n",
        "\n",
        "money = money[['ë…„ì›”', 'ì •ë¶€ëŒ€ì¶œê¸ˆê¸ˆë¦¬', 'í•œêµ­ì€í–‰ ê¸°ì¤€ê¸ˆë¦¬'] ]\n",
        "money.columns = ['ê³„ì•½ë…„ì›”', 'ëŒ€ì¶œê¸ˆë¦¬', 'ê¸°ì¤€ê¸ˆë¦¬']\n",
        "\n",
        "money.loc[money['ê³„ì•½ë…„ì›”'] > 202306,'ëŒ€ì¶œê¸ˆë¦¬'] = money[money['ê³„ì•½ë…„ì›”'] == 202306]['ëŒ€ì¶œê¸ˆë¦¬'].iloc[0]\n",
        "money.loc[money['ê³„ì•½ë…„ì›”'] > 202306,'ê¸°ì¤€ê¸ˆë¦¬'] = money[money['ê³„ì•½ë…„ì›”'] == 202306]['ê¸°ì¤€ê¸ˆë¦¬'].iloc[0]\n",
        "\n",
        "dt_full = dt_full.merge(money, how='left', on='ê³„ì•½ë…„ì›”')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3-3-2-5. ì‹¤ê±°ë˜ì§€ìˆ˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "real_price['ë…„ì›”']=real_price['ë…„ì›”'].astype('str').apply(lambda x: '{:.2f}'.format(float(x)))\n",
        "real_price['ë…„ì›”'] = real_price['ë…„ì›”'].apply(lambda x: datetime.strptime(x, \"%Y.%m\"))\n",
        "real_price['ê³„ì•½ì›”']=real_price['ë…„ì›”'].dt.month\n",
        "real_price['ê³„ì•½ë…„ë„']=real_price['ë…„ì›”'].dt.year\n",
        "real_price.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 6)) \n",
        "plt.plot(real_price['ë…„ì›”'], real_price['ì‹¤ê±°ë˜ì§€ìˆ˜'], marker='o', linestyle='-') \n",
        "plt.title('ì‹¤ê±°ë˜ì§€ìˆ˜ ë³€í™”')  \n",
        "plt.xlabel('ë…„ì›”') \n",
        "plt.ylabel('ì‹¤ê±°ë˜ì§€ìˆ˜') \n",
        "plt.grid(True) \n",
        "plt.xticks(rotation=45)  \n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2023ë…„ 7ì›” ì´í›„ì˜ ì‹¤ê±°ë˜ì§€ìˆ˜ëŠ” ì‚¬ìš©í•˜ë©´ ì•ˆë˜ê¸° ë•Œë¬¸ì— 6ì›”ì˜ ì‹¤ê±°ë˜ì§€ìˆ˜ë¥¼ ê·¸ëŒ€ë¡œ ë°˜ì˜ \n",
        "real_price.loc[(real_price['ê³„ì•½ë…„ë„'] == 2023) & (real_price['ê³„ì•½ì›”'] >= 7), 'ì‹¤ê±°ë˜ì§€ìˆ˜']=real_price[real_price['ë…„ì›”']=='2023-06-01']['ì‹¤ê±°ë˜ì§€ìˆ˜'].values[0]\n",
        "real_price[(real_price['ê³„ì•½ë…„ë„']==2023) & (real_price['ê³„ì•½ì›”']>=7)]\n",
        "\n",
        "dt_full['ê³„ì•½ì›”']=dt_full['ê³„ì•½ì›”'].astype('int')\n",
        "dt_full=pd.merge(dt_full,real_price[['ê³„ì•½ë…„ë„','ê³„ì•½ì›”','ì‹¤ê±°ë˜ì§€ìˆ˜']],on=['ê³„ì•½ë…„ë„','ê³„ì•½ì›”'],how='left')\n",
        "dt_full[['ê³„ì•½ë…„ë„','ê³„ì•½ì›”','ì‹¤ê±°ë˜ì§€ìˆ˜']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3-3-2-6. ì•„íŒŒíŠ¸ì •ë³´ ê²°ì¸¡ì¹˜ ì²˜ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "apart_info = pd.read_parquet(f\"{data_path}/ì•„íŒŒíŠ¸ì •ë³´.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "apart_info = apart_info[apart_info['ì‹œë„'] == 'ì„œìš¸íŠ¹ë³„ì‹œ']\n",
        "apart_info['ë²•ì •ì£¼ì†Œ'] = apart_info['ë²•ì •ë™ì£¼ì†Œ'].str.split(\",\").str[0]\n",
        "apart_info['ì•„íŒŒíŠ¸ì£¼ì†Œ'] = apart_info['ë²•ì •ì£¼ì†Œ'].str.split(\" \").str[0:4].apply(lambda x: \" \".join(x))\n",
        "apart_info['ìŠ¹ê°•ê¸°'] = apart_info[['ìŠ¹ê°•ê¸°(ìŠ¹ê°ìš©)', 'ìŠ¹ê°•ê¸°(í™”ë¬¼ìš©)', 'ìŠ¹ê°•ê¸°(ìŠ¹ê°+í™”ë¬¼)','ìŠ¹ê°•ê¸°(ì¥ì• ì¸)', 'ìŠ¹ê°•ê¸°(ë¹„ìƒìš©)', 'ìŠ¹ê°•ê¸°(ê¸°íƒ€)']].max(axis=1)\n",
        "\n",
        "apart_info['ì°¨ëŸ‰ë³´ìœ ëŒ€ìˆ˜(ì „ì²´)'] = apart_info['ì°¨ëŸ‰ë³´ìœ ëŒ€ìˆ˜(ì „ì²´)'].astype('Int64')\n",
        "apart_info['ì°¨ëŸ‰ë³´ìœ ëŒ€ìˆ˜(ì „ê¸°ì°¨)'] = apart_info['ì°¨ëŸ‰ë³´ìœ ëŒ€ìˆ˜(ì „ê¸°ì°¨)'].astype('Int64')\n",
        "\n",
        "apart_info['ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€ìƒ)'] = apart_info['ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€ìƒ)'].replace(\"í•´ë‹¹ì—†ìŒ\", \"0\")\n",
        "apart_info['ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€í•˜)'] = apart_info['ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€í•˜)'].replace(\"í•´ë‹¹ì—†ìŒ\", \"0\")\n",
        "\n",
        "apart_info['ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€ìƒ)'] = apart_info['ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€ìƒ)'].astype(\"Int64\")\n",
        "apart_info['ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€í•˜)'] = apart_info['ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€í•˜)'].astype(float)\n",
        "\n",
        "apart_info['ì „ê¸°ì¶©ì „ê¸°ì„¤ì¹˜ì—¬ë¶€(ì§€ìƒ)'] = apart_info['ì „ê¸°ì¶©ì „ê¸°ì„¤ì¹˜ì—¬ë¶€(ì§€ìƒ)'].map({\"í•´ë‹¹ì—†ìŒ\":0, \"ì„¤ì¹˜\":1}).astype(\"Int64\")\n",
        "apart_info['ì „ê¸°ì¶©ì „ê¸°ì„¤ì¹˜ì—¬ë¶€(ì§€í•˜)'] = apart_info['ì „ê¸°ì¶©ì „ê¸°ì„¤ì¹˜ì—¬ë¶€(ì§€í•˜)'].map({\"í•´ë‹¹ì—†ìŒ\":0, \"ì„¤ì¹˜\":1}).astype(\"Int64\")\n",
        "apart_info['ì „ê¸°ì¶©ì „ê¸°ì„¤ì¹˜ì—¬ë¶€'] = apart_info['ì „ê¸°ì¶©ì „ê¸°ì„¤ì¹˜ì—¬ë¶€(ì§€ìƒ)'] | apart_info['ì „ê¸°ì¶©ì „ê¸°ì„¤ì¹˜ì—¬ë¶€(ì§€í•˜)']\n",
        "\n",
        "# ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€í•˜) ì»¬ëŸ¼ ì´ìƒì¹˜ ì²˜ë¦¬\n",
        "apart_info.loc[apart_info['ë‹¨ì§€ì½”ë“œ'] == \"A10023343\", 'ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€í•˜)'] = apart_info.loc[apart_info['ë‹¨ì§€ì½”ë“œ'] == \"A10023343\", 'ì´ì£¼ì°¨ëŒ€ìˆ˜']\n",
        "\n",
        "apart_info['ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€í•˜)'] = apart_info['ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€í•˜)'].astype('Int64')\n",
        "\n",
        "apart_info['ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜'] = apart_info['ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€ìƒ)'] + apart_info['ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€í•˜)']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "basic_du = apart_info[apart_info.duplicated(subset='ì•„íŒŒíŠ¸ì£¼ì†Œ', keep=False)]\n",
        "basic_du['ì´ì „ë¶„ì–‘í˜•íƒœ'] = basic_du.groupby('ì•„íŒŒíŠ¸ì£¼ì†Œ')['ë¶„ì–‘í˜•íƒœ'].shift(-1)\n",
        "basic_du = basic_du[~((basic_du['ë¶„ì–‘í˜•íƒœ'].str.contains(\"ë¶„ì–‘|í˜¼í•©\")) & basic_du['ì´ì „ë¶„ì–‘í˜•íƒœ'].str.contains(\"ë¶„ì–‘|í˜¼í•©\"))]\n",
        "\n",
        "apart_info.drop_duplicates(subset='ì•„íŒŒíŠ¸ì£¼ì†Œ', keep=False, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected = ['ë¶„ì–‘í˜•íƒœ', 'ë²•ì •ì£¼ì†Œ', 'ë‹¨ì§€ëª…', 'ë™ìˆ˜', 'ì„¸ëŒ€ìˆ˜', 'ë¶„ì–‘ì„¸ëŒ€ìˆ˜', 'ì„ëŒ€ì„¸ëŒ€ìˆ˜', 'ê´€ë¦¬ë°©ì‹', 'ë‚œë°©ë°©ì‹', 'ë³µë„ìœ í˜•', 'ì‹œê³µì‚¬', 'ì‹œí–‰ì‚¬',\n",
        "'ì¼ë°˜ê´€ë¦¬-ê´€ë¦¬ë°©ì‹', 'ì¼ë°˜ê´€ë¦¬-ì¸ì›', 'ê²½ë¹„ê´€ë¦¬-ê´€ë¦¬ë°©ì‹', 'ê²½ë¹„ê´€ë¦¬-ì¸ì›', 'ì²­ì†Œê´€ë¦¬-ê´€ë¦¬ë°©ì‹', 'ì²­ì†Œê´€ë¦¬-ì¸ì›', 'ê±´ë¬¼êµ¬ì¡°', 'ì „ê¸°-ìˆ˜ì „ìš©ëŸ‰', 'ì „ê¸°-ì„¸ëŒ€ì „ê¸°ê³„ì•½ë°©ì‹',\n",
        "'ìŠ¹ê°•ê¸°', 'ì´ì£¼ì°¨ëŒ€ìˆ˜', 'ì§€ìƒì£¼ì°¨ëŒ€ìˆ˜', 'ì§€í•˜ì£¼ì°¨ëŒ€ìˆ˜', 'CCTVëŒ€ìˆ˜', 'ë¶€ëŒ€ë³µë¦¬ì‹œì„¤', 'ìµœê³ ì¸µìˆ˜','ì§€í•˜ì¸µìˆ˜', 'ì°¨ëŸ‰ë³´ìœ ëŒ€ìˆ˜(ì „ì²´)',\n",
        "'ì°¨ëŸ‰ë³´ìœ ëŒ€ìˆ˜(ì „ê¸°ì°¨)', 'ì „ê¸°ì¶©ì „ê¸°ì„¤ì¹˜ì—¬ë¶€(ì§€ìƒ)', 'ì „ê¸°ì¶©ì „ê¸°ì„¤ì¹˜ì—¬ë¶€(ì§€í•˜)','ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€ìƒ)','ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€í•˜)', 'ì•„íŒŒíŠ¸ì£¼ì†Œ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "AGGREGATIONS = {\n",
        "    'ë¶„ì–‘í˜•íƒœ': 'first',\n",
        "    'ë²•ì •ì£¼ì†Œ': 'first',\n",
        "    'ë‹¨ì§€ëª…': 'first',\n",
        "    'ë™ìˆ˜': 'sum',\n",
        "    'ì„¸ëŒ€ìˆ˜': 'sum',\n",
        "    'ë¶„ì–‘ì„¸ëŒ€ìˆ˜': 'sum',\n",
        "    'ì„ëŒ€ì„¸ëŒ€ìˆ˜': 'sum',\n",
        "    'ê´€ë¦¬ë°©ì‹': 'first',\n",
        "    'ë‚œë°©ë°©ì‹': 'first',\n",
        "    'ë³µë„ìœ í˜•': 'first',\n",
        "    'ì‹œê³µì‚¬': 'first',\n",
        "    'ì‹œí–‰ì‚¬': 'first',\n",
        "    'ì¼ë°˜ê´€ë¦¬-ì¸ì›': 'sum',\n",
        "    'ì²­ì†Œê´€ë¦¬-ì¸ì›': 'sum',\n",
        "    'ì „ê¸°-ìˆ˜ì „ìš©ëŸ‰': 'sum',\n",
        "    'ì „ê¸°-ì„¸ëŒ€ì „ê¸°ê³„ì•½ë°©ì‹': 'first',\n",
        "    'ìŠ¹ê°•ê¸°': 'sum',\n",
        "    'ì´ì£¼ì°¨ëŒ€ìˆ˜': 'sum',\n",
        "    'ì§€ìƒì£¼ì°¨ëŒ€ìˆ˜': 'sum',\n",
        "    'ì§€í•˜ì£¼ì°¨ëŒ€ìˆ˜': 'sum',\n",
        "    'CCTVëŒ€ìˆ˜': 'sum',\n",
        "    'ë¶€ëŒ€ë³µë¦¬ì‹œì„¤': 'first',\n",
        "    'ìµœê³ ì¸µìˆ˜': 'max',\n",
        "    'ì§€í•˜ì¸µìˆ˜': 'max',\n",
        "    'ì°¨ëŸ‰ë³´ìœ ëŒ€ìˆ˜(ì „ì²´)': 'sum',\n",
        "    'ì°¨ëŸ‰ë³´ìœ ëŒ€ìˆ˜(ì „ê¸°ì°¨)': 'sum',\n",
        "    'ì „ê¸°ì¶©ì „ê¸°ì„¤ì¹˜ì—¬ë¶€(ì§€ìƒ)': 'max',\n",
        "    'ì „ê¸°ì¶©ì „ê¸°ì„¤ì¹˜ì—¬ë¶€(ì§€ìƒ)': 'max',\n",
        "    'ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€ìƒ)': 'sum',\n",
        "    'ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€í•˜)': 'sum',\n",
        "}\n",
        "\n",
        "basic_du = basic_du[selected].groupby('ì•„íŒŒíŠ¸ì£¼ì†Œ').agg(AGGREGATIONS).reset_index()\n",
        "basic_du['ë¶„ì–‘í˜•íƒœ'] = 'í˜¼í•©'\n",
        "\n",
        "apart_info = pd.concat([apart_info, basic_du], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full['ì•„íŒŒíŠ¸ì£¼ì†Œ'] = dt_full['ì‹œêµ°êµ¬'] + \" \" + dt_full['ë²ˆì§€']\n",
        "dt_full = dt_full.merge(apart_info[selected], how='left', on='ì•„íŒŒíŠ¸ì£¼ì†Œ')\n",
        "dt_full.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì¹´í…Œê³ ë¦¬ê°€ ë‹¬ë¼ì„œ ë§µí•‘í•´ì£¼ê¸°\n",
        "dt_full['ë¶„ì–‘í˜•íƒœ'] = dt_full['ë¶„ì–‘í˜•íƒœ'].map({\"ë¶„ì–‘\": \"ë¶„ì–‘\", \"í˜¼í•©\": \"ê¸°íƒ€\", \"ì„ëŒ€\": \"ì„ëŒ€\"})\n",
        "index = dt_full[dt_full['k_ì„¸ëŒ€íƒ€ì…ë¶„ì–‘í˜•íƒœ'].isna()].index\n",
        "dt_full.loc[index, 'k_ì„¸ëŒ€íƒ€ì…ë¶„ì–‘í˜•íƒœ'] = dt_full.loc[index, 'ë¶„ì–‘í˜•íƒœ']\n",
        "\n",
        "# ì¹´í…Œê³ ë¦¬ê°€ ë‹¬ë¼ì„œ ë§µí•‘í•´ì£¼ê¸°\n",
        "dt_full['ê´€ë¦¬ë°©ì‹'] = dt_full['ê´€ë¦¬ë°©ì‹'].map({\"ìœ„íƒê´€ë¦¬\": \"ìœ„íƒê´€ë¦¬\", \"ìì¹˜ê´€ë¦¬\": \"ìì¹˜ê´€ë¦¬\", \"ìœ„íƒê´€ë¦¬(ì§ì˜+ìœ„íƒ)\": \"ì§ì˜\", \"ìì¹˜ê´€ë¦¬(ì§ì˜)\": \"ì§ì˜\", \"ìœ„íƒê´€ë¦¬(ì´ì•¡ê´€ë¦¬ì œ)\": \"ì§ì˜\", \"ê´€ë¦¬ë°©ì‹ë¯¸ì •\":np.nan})\n",
        "index = dt_full[dt_full['k_ê´€ë¦¬ë°©ì‹'].isna()].index\n",
        "dt_full.loc[index, 'k_ê´€ë¦¬ë°©ì‹'] = dt_full.loc[index, 'ê´€ë¦¬ë°©ì‹']\n",
        "\n",
        "index = dt_full[dt_full['k_ë³µë„ìœ í˜•'].isna()].index\n",
        "dt_full.loc[index, 'k_ë³µë„ìœ í˜•'] = dt_full.loc[index, 'ë³µë„ìœ í˜•']\n",
        "\n",
        "index = dt_full[dt_full['k_ë‚œë°©ë°©ì‹'].isna()].index\n",
        "dt_full.loc[index, 'k_ë‚œë°©ë°©ì‹'] = dt_full.loc[index, 'ë‚œë°©ë°©ì‹']\n",
        "\n",
        "index = dt_full[dt_full['k_ì „ì²´ë™ìˆ˜'].isna()].index\n",
        "dt_full.loc[index, 'k_ì „ì²´ë™ìˆ˜'] = dt_full.loc[index, 'ë™ìˆ˜']\n",
        "\n",
        "index = dt_full[dt_full['k_ì „ì²´ì„¸ëŒ€ìˆ˜'].isna()].index\n",
        "dt_full.loc[index, 'k_ì „ì²´ì„¸ëŒ€ìˆ˜'] = dt_full.loc[index, 'ì„¸ëŒ€ìˆ˜']\n",
        "\n",
        "index = dt_full[dt_full['k_ê±´ì„¤ì‚¬ì‹œê³µì‚¬'].isna()].index\n",
        "dt_full.loc[index, 'k_ê±´ì„¤ì‚¬ì‹œê³µì‚¬'] = dt_full.loc[index, 'ì‹œê³µì‚¬']\n",
        "\n",
        "index = dt_full[dt_full['k_ì‹œí–‰ì‚¬'].isna()].index\n",
        "dt_full.loc[index, 'k_ì‹œí–‰ì‚¬'] = dt_full.loc[index, 'ì‹œí–‰ì‚¬']\n",
        "\n",
        "index = dt_full[dt_full['ì„¸ëŒ€ì „ê¸°ê³„ì•½ë°©ë²•'].isna()].index\n",
        "dt_full.loc[index, 'ì„¸ëŒ€ì „ê¸°ê³„ì•½ë°©ë²•'] = dt_full.loc[index, 'ì „ê¸°-ì„¸ëŒ€ì „ê¸°ê³„ì•½ë°©ì‹']\n",
        "\n",
        "# ì›ë³¸ ë°ì´í„°ì— ì´ìƒì¹˜ê°€ ë„ˆë¬´ ë§ì•„ì„œ ì¡°ê¸ˆ ì œê±°\n",
        "dt_full[dt_full['ì£¼ì°¨ëŒ€ìˆ˜'] < dt_full['k_ì „ì²´ì„¸ëŒ€ìˆ˜'].quantile(0.01)]['ì£¼ì°¨ëŒ€ìˆ˜'] = np.nan\n",
        "\n",
        "index = dt_full[dt_full['ì£¼ì°¨ëŒ€ìˆ˜'].isna()].index\n",
        "dt_full.loc[index, 'ì£¼ì°¨ëŒ€ìˆ˜'] = dt_full.loc[index, 'ì´ì£¼ì°¨ëŒ€ìˆ˜']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "drop_cols2 = ['ë¶„ì–‘í˜•íƒœ', 'ê´€ë¦¬ë°©ì‹', 'ì¼ë°˜ê´€ë¦¬-ê´€ë¦¬ë°©ì‹', 'ê²½ë¹„ê´€ë¦¬-ê´€ë¦¬ë°©ì‹', 'ì²­ì†Œê´€ë¦¬-ê´€ë¦¬ë°©ì‹', 'ê±´ë¬¼êµ¬ì¡°',\n",
        "             'ë³µë„ìœ í˜•', 'ë‚œë°©ë°©ì‹', 'ë™ìˆ˜', 'ì„¸ëŒ€ìˆ˜', 'ì‹œê³µì‚¬', 'ì‹œí–‰ì‚¬', 'ì „ê¸°-ì„¸ëŒ€ì „ê¸°ê³„ì•½ë°©ì‹', \n",
        "             'ì´ì£¼ì°¨ëŒ€ìˆ˜', 'ë¶€ëŒ€ë³µë¦¬ì‹œì„¤', 'ì „ê¸°ì¶©ì „ê¸°ì„¤ì¹˜ì—¬ë¶€(ì§€ìƒ)', 'ì „ê¸°ì¶©ì „ê¸°ì„¤ì¹˜ì—¬ë¶€(ì§€í•˜)', \n",
        "             'ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€ìƒ)', 'ì „ê¸°ì°¨ì „ìš©ì£¼ì°¨ë©´ìˆ˜(ì§€í•˜)']\n",
        "dt_full.drop(columns=drop_cols2, inplace=True)\n",
        "dt_full.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full[\"ê³„ì•½ë…„ì›”ì¼\"] = dt_full[\"ê³„ì•½ë…„ì›”\"].astype(str) + dt_full[\"ê³„ì•½ì¼\"].astype(str)\n",
        "dt_full[\"ê³„ì•½ë…„ì›”ì¼\"] = pd.to_datetime(dt_full['ê³„ì•½ë…„ì›”ì¼'], format='%Y%m%d')\n",
        "\n",
        "dt_full['ê³„ì•½ë…„'] = dt_full['ê³„ì•½ë…„ì›”'].astype('str').map(lambda x : x[:4])\n",
        "dt_full['ê³„ì•½ì›”'] = dt_full['ê³„ì•½ë…„ì›”'].astype('str').map(lambda x : x[4:])\n",
        "\n",
        "dt_full['í’€ì•„íŒŒíŠ¸ëª…'] = dt_full['ì‹œêµ°êµ¬'] + \" \" + dt_full['ì•„íŒŒíŠ¸ëª…']\n",
        "\n",
        "dt_full['ì£¼ì†Œ'] = dt_full['ì‹œêµ°êµ¬'] + \" \" + dt_full['ë²ˆì§€']\n",
        "\n",
        "dt_full['êµ¬'] = dt_full['ì‹œêµ°êµ¬'].map(lambda x : x.split()[1])\n",
        "dt_full['ë™'] = dt_full['ì‹œêµ°êµ¬'].map(lambda x : x.split()[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full['í‰ë‹¨ê°€'] = dt_full['target'] / dt_full['ì „ìš©ë©´ì '] * 0.3025\n",
        "\n",
        "target_encoding = dt_full.groupby('êµ¬')['í‰ë‹¨ê°€'].mean()\n",
        "dt_full['êµ¬í‰ë‹¨ê°€'] = dt_full['êµ¬'].map(target_encoding)\n",
        "\n",
        "target_encoding = dt_full.groupby('ë™')['í‰ë‹¨ê°€'].mean()\n",
        "dt_full['ë™í‰ë‹¨ê°€'] = dt_full['ë™'].map(target_encoding)\n",
        "\n",
        "dt_full['êµ¬ìˆœìœ„'] = dt_full['êµ¬í‰ë‹¨ê°€'].rank(method='dense')\n",
        "dt_full['ë™ìˆœìœ„'] = dt_full['ë™í‰ë‹¨ê°€'].rank(method='dense')\n",
        "\n",
        "target_encoding = dt_full.groupby('í’€ì•„íŒŒíŠ¸ëª…')['í‰ë‹¨ê°€'].mean()\n",
        "dt_full['ì•„íŒŒíŠ¸í‰ë‹¨ê°€'] = dt_full['í’€ì•„íŒŒíŠ¸ëª…'].map(target_encoding)\n",
        "dt_full['ì•„íŒŒíŠ¸ìˆœìœ„'] = dt_full['ì•„íŒŒíŠ¸í‰ë‹¨ê°€'].rank(method='dense')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full['ê³„ì•½ë…„ì›”3'] = pd.to_datetime(dt_full['ê³„ì•½ë…„ì›”ì¼']).dt.to_period(\"Q\").dt.to_timestamp()\n",
        "temp = dt_full.groupby(['í’€ì•„íŒŒíŠ¸ëª…', 'ê³„ì•½ë…„ì›”3'])['í‰ë‹¨ê°€'].mean().reset_index(name=\"3ì›”í‰ë‹¨ê°€\")\n",
        "\n",
        "AGG = {'3ì›”í‰ë‹¨ê°€': [ 'std', 'skew', ('kurt', lambda x: x.kurt())]}\n",
        "temp = temp.groupby('í’€ì•„íŒŒíŠ¸ëª…').agg(AGG)\n",
        "temp.columns = ['_'.join(col).strip() for col in temp.columns.values]\n",
        "dt_full = dt_full.merge(temp, on='í’€ì•„íŒŒíŠ¸ëª…', how='left')\n",
        "del dt_full['ê³„ì•½ë…„ì›”3']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gangnam = ['ê°•ì„œêµ¬', 'ì˜ë“±í¬êµ¬', 'ë™ì‘êµ¬', 'ì„œì´ˆêµ¬', 'ê°•ë‚¨êµ¬', 'ì†¡íŒŒêµ¬', 'ê°•ë™êµ¬']\n",
        "\n",
        "# 'êµ¬' ì—´ì— ëŒ€í•´ ê°•ë‚¨ ì—¬ë¶€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” 'ê°•ë‚¨ì—¬ë¶€' ì—´ ìƒì„±\n",
        "dt_full['ê°•ë‚¨ì—¬ë¶€'] = dt_full['êµ¬'].apply(lambda x: 1 if x in gangnam else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full['ì‹ ì¶•ì—¬ë¶€'] = dt_full['ê±´ì¶•ë…„ë„'].apply(lambda x: 1 if x >= 2009 else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full['ì„¸ëŒ€ë‹¹ì£¼ì°¨ëŒ€ìˆ˜'] = dt_full['ì£¼ì°¨ëŒ€ìˆ˜'] / dt_full['k_ì „ì²´ì„¸ëŒ€ìˆ˜']\n",
        "dt_full['ì„¸ëŒ€ë‹¹ìŠ¹ê°•ê¸°ëŒ€ìˆ˜'] = dt_full['ìŠ¹ê°•ê¸°'] / dt_full['k_ì „ì²´ì„¸ëŒ€ìˆ˜'] \n",
        "dt_full['ê³ ì¸µë„'] = dt_full['ì¸µ'] / dt_full['ìµœê³ ì¸µìˆ˜']\n",
        "dt_full['ë™ì„¸ëŒ€ìˆ˜'] = dt_full['k_ì „ì²´ì„¸ëŒ€ìˆ˜'] / dt_full['k_ì „ì²´ë™ìˆ˜']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì›”ë³„ ê±´ìˆ˜\n",
        "temp = dt_full.groupby(['í’€ì•„íŒŒíŠ¸ëª…', 'ê³„ì•½ë…„ì›”']).size().reset_index(name='ì›”ê±°ë˜ê±´ìˆ˜')\n",
        "dt_full = dt_full.merge(temp, how='left', on=['í’€ì•„íŒŒíŠ¸ëª…', 'ê³„ì•½ë…„ì›”'])\n",
        "\n",
        "AGG = {'ì›”ê±°ë˜ê±´ìˆ˜': ['mean', 'std', 'skew', ('kurt', lambda x: x.kurt())]}\n",
        "temp = temp.groupby('í’€ì•„íŒŒíŠ¸ëª…').agg(AGG)\n",
        "temp.columns = ['_'.join(col).strip() for col in temp.columns.values]\n",
        "\n",
        "dt_full = dt_full.merge(temp, on='í’€ì•„íŒŒíŠ¸ëª…', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ìµœê·¼ 5ë…„ ê±´ìˆ˜\n",
        "train_max_date = dt_full[dt_full[\"is_test\"] == 0]['ê³„ì•½ë…„ì›”ì¼'].max()\n",
        "lag5year = dt_full[dt_full['ê³„ì•½ë…„ì›”ì¼'] > train_max_date - pd.DateOffset(years=5)]\n",
        "\n",
        "target_encoding = lag5year.groupby('í’€ì•„íŒŒíŠ¸ëª…')['ê³„ì•½ë…„ì›”ì¼'].size()\n",
        "dt_full['ì•„íŒŒíŠ¸ê±°ë˜íšŸìˆ˜5'] = dt_full['í’€ì•„íŒŒíŠ¸ëª…'].map(target_encoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "AGG = {'ì „ìš©ë©´ì ':['mean', 'std', ('kurt', lambda x: x.kurt()), 'size']}\n",
        "temp = dt_full.groupby('í’€ì•„íŒŒíŠ¸ëª…').agg(AGG)\n",
        "temp.columns = ['_'.join(col).strip() for col in temp.columns.values]\n",
        "dt_full = dt_full.merge(temp, how='left', on='í’€ì•„íŒŒíŠ¸ëª…')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full['ì „ìš©ë©´ì ë²”ì£¼'] = pd.cut(dt_full['ì „ìš©ë©´ì '], bins=[0, 40, 60, 85, 135, float('inf')], labels=[0, 1, 2, 3, 4], right=False)\n",
        "dt_full['ì „ìš©ë©´ì ë²”ì£¼']=dt_full['ì „ìš©ë©´ì ë²”ì£¼'].astype('int')\n",
        "\n",
        "temp = dt_full.pivot_table(index='í’€ì•„íŒŒíŠ¸ëª…', columns='ì „ìš©ë©´ì ë²”ì£¼', aggfunc='size', fill_value=0)\n",
        "temp.columns = [temp.columns.name+\"_\"+str(col) for col in temp.columns.values]\n",
        "dt_full = dt_full.merge(temp, how='left', on='í’€ì•„íŒŒíŠ¸ëª…')\n",
        "\n",
        "dt_full['ë²”ì£¼4ë¹„ìœ¨'] = dt_full['ì „ìš©ë©´ì ë²”ì£¼_4'] / dt_full['ì „ìš©ë©´ì _size']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp = dt_full.copy()\n",
        "temp = temp.sort_values(by=['í’€ì•„íŒŒíŠ¸ëª…', 'ê³„ì•½ë…„ì›”ì¼'])\n",
        "temp['ì•„íŒŒíŠ¸ì´ì „ê³„ì•½ì¼'] = temp.groupby('í’€ì•„íŒŒíŠ¸ëª…')['ê³„ì•½ë…„ì›”ì¼'].shift(1)\n",
        "dt_full.loc[temp.index, 'ì•„íŒŒíŠ¸ì´ì „ê³„ì•½ì¼'] = temp['ì•„íŒŒíŠ¸ì´ì „ê³„ì•½ì¼']\n",
        "dt_full['ì´ì „ê³„ì•½_diff'] =  (dt_full['ê³„ì•½ë…„ì›”ì¼'] - dt_full['ì•„íŒŒíŠ¸ì´ì „ê³„ì•½ì¼']).dt.days\n",
        "\n",
        "del dt_full['ì•„íŒŒíŠ¸ì´ì „ê³„ì•½ì¼']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3-3-2-7. ê¶Œì—­ë³„ í‰ê·  ì†Œë“"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def map_region(district):\n",
        "\n",
        "    region_mapping = {\n",
        "    'ë™ë‚¨ê¶Œ': ['ê°•ë‚¨êµ¬', 'ì„œì´ˆêµ¬', 'ì†¡íŒŒêµ¬', 'ê°•ë™êµ¬'],\n",
        "    'ì„œë‚¨ê¶Œ': ['ë™ì‘êµ¬', 'ê´€ì•…êµ¬', 'ê¸ˆì²œêµ¬', 'ì˜ë“±í¬êµ¬', 'êµ¬ë¡œêµ¬', 'ì–‘ì²œêµ¬', 'ê°•ì„œêµ¬'],\n",
        "    'ì„œë¶ê¶Œ': ['ì€í‰êµ¬', 'ì„œëŒ€ë¬¸êµ¬', 'ë§ˆí¬êµ¬'],\n",
        "    'ë„ì‹¬ê¶Œ': ['ì¢…ë¡œêµ¬', 'ì¤‘êµ¬', 'ìš©ì‚°êµ¬'],\n",
        "    'ë™ë¶ê¶Œ': ['ì„±ë™êµ¬', 'ê´‘ì§„êµ¬', 'ë™ëŒ€ë¬¸êµ¬', 'ì¤‘ë‘êµ¬','ì„±ë¶êµ¬', 'ê°•ë¶êµ¬', 'ë„ë´‰êµ¬', 'ë…¸ì›êµ¬']\n",
        "    }\n",
        "\n",
        "    for region, districts in region_mapping.items():\n",
        "        if district in districts:\n",
        "            return region\n",
        "    return 'ê¸°íƒ€'  # ë§Œì•½ ë§¤í•‘ë˜ì§€ ì•ŠëŠ” êµ¬ê°€ ìˆë‹¤ë©´ 'ê¸°íƒ€'ë¡œ ë¶„ë¥˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_5_regions = income[income['íŠ¹ì„±ë³„(1)'] == '5ê¶Œì—­ë³„']\n",
        "dt_full['ê¶Œì—­'] = dt_full['êµ¬'].map(map_region)\n",
        "\n",
        "sorted_df = df_5_regions.sort_values(by='2020.7', ascending=False)\n",
        "sorted_df['2020.7'] =sorted_df['2020.7'].astype('float')  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "income_data = sorted_df.set_index('íŠ¹ì„±ë³„(2)')['2020.7'].to_dict()\n",
        "min_income = min(income_data.values())\n",
        "max_income = max(income_data.values())\n",
        "\n",
        "def normalize_income(income):\n",
        "    return (income - min_income) / (max_income - min_income)\n",
        "\n",
        "normalized_scores = {region: normalize_income(income) for region, income in income_data.items()}\n",
        "\n",
        "dt_full['income'] = dt_full['ê¶Œì—­'].map(normalized_scores)\n",
        "dt_full.drop(columns=['ê¶Œì—­'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3-3-3. ìµœê·¼ê±°ë˜ê°€ ì¶”ê°€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_group(group):\n",
        "    matching_rows = group.sort_values(by=['ê³„ì•½ë…„ì›”ì¼'])[['idx', 'ì•„íŒŒíŠ¸ëª…', 'ì „ìš©ë©´ì ë²”ì£¼', 'target', 'ê³„ì•½ë…„ì›”ì¼']]\n",
        "    matching_rows['ìµœê·¼ê±°ë˜ê°€'] = matching_rows['target'].shift(1)\n",
        "    return matching_rows\n",
        "\n",
        "dt_full['idx']=dt_full.index\n",
        "dt_tmp = []\n",
        "for _, group in tqdm(dt_full.groupby(['êµ¬', 'ì•„íŒŒíŠ¸ëª…', 'ì „ìš©ë©´ì ë²”ì£¼'])):\n",
        "    dt_tmp.append(process_group(group))\n",
        "dt_tmp = pd.concat(dt_tmp, ignore_index=True)\n",
        "dt_tmp.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full = pd.merge(dt_full, dt_tmp[['idx', 'ìµœê·¼ê±°ë˜ê°€']], left_on='idx', right_on='idx', how='left')\n",
        "dt_full.reset_index(drop=True, inplace=True)\n",
        "#dt_full[dt_full['ì•„íŒŒíŠ¸ëª…']=='ë°˜í¬ìì´'].sort_values(by='ê³„ì•½ì¼ì')[['ì „ìš©ë©´ì ','ê³„ì•½ì¼ì','target','ìµœê·¼ê±°ë˜ê°€']].head(50)\n",
        "dt_full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full['ìµœê·¼ê±°ë˜ê°€'] = dt_full['ìµœê·¼ê±°ë˜ê°€'].fillna(dt_full.groupby(['ì•„íŒŒíŠ¸ëª…', 'ë™','ì „ìš©ë©´ì ë²”ì£¼'])['target'].transform('mean'))\n",
        "#dt_full2[dt_full2['ì•„íŒŒíŠ¸ëª…']=='ê°œí¬6ì°¨ìš°ì„±'].sort_values(by='ê³„ì•½ì¼ì')[['ì „ìš©ë©´ì ','ê³„ì•½ì¼ì','target','ìµœê·¼ê±°ë˜ê°€']]\n",
        "dt_full['ìµœê·¼ê±°ë˜ê°€'] = dt_full['ìµœê·¼ê±°ë˜ê°€'].fillna(dt_full.groupby(['ì•„íŒŒíŠ¸ëª…', 'ë™'])['target'].transform('mean'))\n",
        "dt_full['ìµœê·¼ê±°ë˜ê°€'] = dt_full['ìµœê·¼ê±°ë˜ê°€'].fillna(dt_full.groupby(['ë™'])['target'].transform('mean'))\n",
        "dt_full[dt_full['ìµœê·¼ê±°ë˜ê°€'].isna()==1]\n",
        "dt_full.drop(['idx'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full_bak2=dt_full.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3-4. ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_col = []\n",
        "cat_col = []\n",
        "rest = []\n",
        "\n",
        "for column in dt_full.columns:\n",
        "    if pd.api.types.is_numeric_dtype(dt_full[column]):\n",
        "        num_col.append(column)\n",
        "    elif pd.api.types.is_object_dtype(dt_full[column]):\n",
        "        cat_col.append(column)\n",
        "    else:\n",
        "        rest.append(column)\n",
        "\n",
        "print(\"ì—°ì†í˜• ë³€ìˆ˜:\", num_col)\n",
        "print(\"ë²”ì£¼í˜• ë³€ìˆ˜:\", cat_col)\n",
        "print(\"ë‚˜ë¨¸ì§€ ë³€ìˆ˜:\", rest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full = dt_full.replace('-', np.nan)\n",
        "\n",
        "for col in cat_col:\n",
        "    mode_fill_value = dt_full[col].mode().iloc[0]\n",
        "    dt_full[col] = dt_full[col].fillna(mode_fill_value)\n",
        "\n",
        "# mean_colsì— ìˆëŠ” ê° ì»¬ëŸ¼ë“¤ì˜ ê²°ì¸¡ì¹˜ë¥¼ í•´ë‹¹ ì»¬ëŸ¼ì˜ í‰ê· ê°’ìœ¼ë¡œ ì±„ìš°ê¸°\n",
        "for col in num_col:\n",
        "    try:\n",
        "        mean_fill_value = dt_full[col].mean()\n",
        "        dt_full[col] = dt_full[col].fillna(mean_fill_value)\n",
        "    except:pass\n",
        "dt_full.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "drop_cols3 = ['ê³„ì•½ë…„ì›”',\"ê³„ì•½ë…„ë„\",\n",
        "             'í‰ë‹¨ê°€', 'ë™í‰ë‹¨ê°€', 'êµ¬í‰ë‹¨ê°€', 'ì•„íŒŒíŠ¸í‰ë‹¨ê°€',\n",
        "             'ì•„íŒŒíŠ¸ì£¼ì†Œ', 'ë²•ì •ì£¼ì†Œ', 'ë‹¨ì§€ëª…',\n",
        "             'ê±´ì¶•ë©´ì ', 'k_ì„¸ëŒ€íƒ€ì…ë¶„ì–‘í˜•íƒœ', 'ì›”ê±°ë˜ê±´ìˆ˜',\n",
        "             ]\n",
        "dt_full.drop(columns=drop_cols3, inplace=True)\n",
        "dt_full.columns\n",
        "dt_full_bak3=dt_full.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full_bak3.to_csv(f\"{data_path}/dt_full_ëª¨ë¸ë§.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXfXRevr3dfe"
      },
      "source": [
        "# 4. Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ëª¨ë¸ ì €ì¥ ë° ë¡œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_model(name,model):\n",
        "    with open(f'{model_path}/{name}.pkl', 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "    print(\"Save Success\")\n",
        "    \n",
        "def load_model(name):\n",
        "    with open(f'{model_path}/{name}.pkl', 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4-1. LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full=pd.read_csv(f\"{data_path}/dt_full_ëª¨ë¸ë§.csv\")\n",
        "\n",
        "Logtarget=True # íƒ€ê²Ÿê³¼ ìµœê·¼ê±°ë˜ê°€ë¥¼ ë¡œê·¸í™”í• ì§€ ë§ì§€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-1-1.íƒ€ê²Ÿ ë¡œê·¸í™”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if(Logtarget==True):\n",
        "    print(\"Target and recenttarget log transform\")\n",
        "    dt_full['target']=np.log1p(dt_full['target'])\n",
        "    try: dt_full['ìµœê·¼ê±°ë˜ê°€']=np.log1p(dt_full['ìµœê·¼ê±°ë˜ê°€'])\n",
        "    except:pass\n",
        "\n",
        "def transform_log(pred,target=None):\n",
        "    if(Logtarget==True):\n",
        "        return np.expm1(pred),np.expm1(target)\n",
        "    else:\n",
        "        return pred,target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-1-1.ë…„ë„ ì œê±°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dt_full=dt_full[dt_full['ê³„ì•½ë…„ë„']>2019]\n",
        "# dt_full.reset_index(drop=True,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-1-3.ìµœì¢… drop ì»¬ëŸ¼ ê²°ì •í•˜ê¸° "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "drop_cols4=['ìµœê·¼ê±°ë˜ê°€','ì‹¤ê±°ë˜ì§€ìˆ˜']\n",
        "dt_full.drop(drop_cols4,axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-1-4. Train, Test ë¶„ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_train = dt_full[dt_full['is_test']==0]\n",
        "dt_test = dt_full[dt_full['is_test']==1]\n",
        "dt_test['target'] = 0\n",
        "\n",
        "dt_train.drop(['is_test'], axis = 1, inplace=True)\n",
        "dt_test.drop(['is_test'], axis = 1, inplace=True)\n",
        "print(dt_train.shape, dt_test.shape)\n",
        "assert dt_train.shape[1] == dt_test.shape[1] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-1-5. ë¼ë²¨ ì¸ì½”ë”©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cols,cat_cols,rest = [],[],[]\n",
        "\n",
        "for column in dt_train.columns:\n",
        "    if pd.api.types.is_numeric_dtype(dt_train[column]): num_cols.append(column) # \n",
        "    elif pd.api.types.is_object_dtype(dt_train[column]): cat_cols.append(column)\n",
        "    else: rest.append(column)\n",
        "    \n",
        "print(\"ì—°ì†í˜• ë³€ìˆ˜:\", num_cols)\n",
        "print(\"ë²”ì£¼í˜• ë³€ìˆ˜:\", cat_cols)\n",
        "print(\"ë‚˜ë¨¸ì§€ ë³€ìˆ˜:\", rest)\n",
        "\n",
        "label_encoders = {}\n",
        "\n",
        "for col in tqdm(cat_cols):\n",
        "    if(col=='ê³„ì•½ë…„ì›”ì¼'):continue\n",
        "    lbl = LabelEncoder()\n",
        "    lbl.fit( dt_train[col].astype(str) )\n",
        "    dt_train[col] = lbl.transform(dt_train[col].astype(str))\n",
        "    label_encoders[col] = lbl          \n",
        "    for label in np.unique(dt_test[col]):\n",
        "        if label not in lbl.classes_: \n",
        "            lbl.classes_ = np.append(lbl.classes_, label) \n",
        "    dt_test[col] = lbl.transform(dt_test[col].astype(str))\n",
        ";"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-1-6. LGBM ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = dt_train[dt_train['ê³„ì•½ë…„ì›”ì¼'] < '2023-01-01'].drop(columns=['target', 'ê³„ì•½ë…„ì›”ì¼'])\n",
        "X_val = dt_train[dt_train['ê³„ì•½ë…„ì›”ì¼'] >= '2023-01-01'].drop(columns=['target', 'ê³„ì•½ë…„ì›”ì¼'])\n",
        "y_train = dt_train[dt_train['ê³„ì•½ë…„ì›”ì¼'] < '2023-01-01']['target']\n",
        "y_val = dt_train[dt_train['ê³„ì•½ë…„ì›”ì¼'] >= '2023-01-01']['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gbm = lgb.LGBMRegressor(n_estimators=100000,                # early stoppingì„ ì ìš©í•˜ê¸°ì— ì ë‹¹íˆ ë§ì€ ë°˜ë³µ íšŸìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
        "                        metric=\"rmse\",\n",
        "                        data_sample_strategy='goss',        # sampling ë°©ë²•ì„ gossë¡œ ì ìš©í•©ë‹ˆë‹¤.\n",
        "                        max_depth=15,                       # defaultê°’ì¸ 20ì—ì„œ 12ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\n",
        "                        num_leaves=2**7-1,                  # defaultê°’ì¸ 31ì—ì„œ 62ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤. 2**depth > 2**5-1\n",
        "                        # min_data_in_leaf=40,              # defaultê°’ì¸ 20ì—ì„œ 40ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\n",
        "                        min_child_samples=40,               # defaultê°’ì¸ 20ì—ì„œ 40ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\n",
        "                        colsample_bytree= 0.7,\n",
        "                        subsample=0.7,\n",
        "                        learning_rate=0.15,\n",
        "                        random_state=42,\n",
        "                        )\n",
        "gbm.fit(X_train, y_train,\n",
        "        eval_set=[(X_train, y_train), (X_val, y_val)],\n",
        "        eval_metric ='rmse',\n",
        "        categorical_feature=\"auto\",\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=50),         # early stoppingì„ ì ìš©í•©ë‹ˆë‹¤. 50ë²ˆë™ì•ˆ metircì˜ ê°œì„ ì´ ì—†ë‹¤ë©´ í•™ìŠµì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\n",
        "                   lgb.log_evaluation(period=10, show_stdv=True)]  # 10ë²ˆì˜ ë°˜ë³µë§ˆë‹¤ í‰ê°€ì ìˆ˜ë¥¼ ë¡œê·¸ì— ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
        ")\n",
        "model_path='../model' \n",
        "save_model(\"lgbm_log\",gbm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_pred=gbm.predict(X_val)\n",
        "val_pred,y_val=transform_log(val_pred,y_val)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
        "\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.title(\"ê²€ì¦ ë°ì´í„°\")\n",
        "plt.text(0.5, 0.9, f'RMSE: {rmse:.2f}', fontsize=20, ha='center', transform=plt.gca().transAxes)\n",
        "sns.lineplot(y_val.reset_index(drop=True), label='target', alpha=1)\n",
        "sns.lineplot(val_pred, label='pred', alpha=1)\n",
        "plt.grid()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "importances = pd.Series(gbm.feature_importances_, index=list(X_train.columns))\n",
        "importances = importances.sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 16))\n",
        "plt.title(\"Feature Importances\")\n",
        "sns.barplot(x=importances, y=importances.index)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-1-7. LGBM ëª¨ë¸ ì¶”ë¡ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test = dt_test.drop(columns=['target', 'ê³„ì•½ë…„ì›”ì¼'])\n",
        "test_pred = gbm.predict(X_test)\n",
        "test_pred,_=transform_log(test_pred,0)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n",
        "\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.title(\"í…ŒìŠ¤íŠ¸ ë°ì´í„°\")\n",
        "plt.text(0.5, 0.9, f'RMSE: {rmse:.2f}', fontsize=20, ha='center', transform=plt.gca().transAxes)\n",
        "sns.lineplot(y_test.reset_index(drop=True), label='ì‹¤ì œê°’', alpha=1)\n",
        "sns.lineplot(test_pred, label='ì˜ˆì¸¡ê°’', alpha=1)\n",
        "plt.grid()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4-2.Catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full=pd.read_csv(f\"{data_path}/dt_full_ëª¨ë¸ë§.csv\")\n",
        "\n",
        "Logtarget=True # íƒ€ê²Ÿê³¼ ìµœê·¼ê±°ë˜ê°€ë¥¼ ë¡œê·¸í™”í• ì§€ ë§ì§€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-2-1. íƒ€ê²Ÿ ë¡œê·¸í™”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if(Logtarget==True):\n",
        "    print(\"Target and recenttarget log transform\")\n",
        "    dt_full['target']=np.log1p(dt_full['target'])\n",
        "    try: dt_full['ìµœê·¼ê±°ë˜ê°€']=np.log1p(dt_full['ìµœê·¼ê±°ë˜ê°€'])\n",
        "    except:pass\n",
        "\n",
        "def transform_log(pred,target=None):\n",
        "    if(Logtarget==True):\n",
        "        return np.expm1(pred),np.expm1(target)\n",
        "    else:\n",
        "        return pred,target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-2-2. ë…„ë„ ì œê±°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full=dt_full[dt_full['ê³„ì•½ë…„']>2019]\n",
        "dt_full.reset_index(drop=True,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-2-3. ìµœì¢… drop ì»¬ëŸ¼ ê²°ì •í•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "drop_cols4=['ì‹œêµ°êµ¬', 'ë²ˆì§€', 'ë³¸ë²ˆ', 'ë¶€ë²ˆ', 'ì „ìš©ë©´ì ', 'ê³„ì•½ì¼', 'ë„ë¡œëª…',\n",
        "       'ê±°ë˜ìœ í˜•', 'k_ê´€ë¦¬ë°©ì‹', 'k_ë³µë„ìœ í˜•', 'k_ë‚œë°©ë°©ì‹', 'k_ì „ì²´ë™ìˆ˜', 'k_ì „ì²´ì„¸ëŒ€ìˆ˜', 'k_ê±´ì„¤ì‚¬ì‹œê³µì‚¬',\n",
        "       'k_ì‹œí–‰ì‚¬', 'k_ì—°ë©´ì ', 'k_ì£¼ê±°ì „ìš©ë©´ì ', 'k_ê´€ë¦¬ë¹„ë¶€ê³¼ë©´ì ', 'k_ì „ìš©ë©´ì ë³„ì„¸ëŒ€í˜„í™©60ì´í•˜',\n",
        "       'k_ì „ìš©ë©´ì ë³„ì„¸ëŒ€í˜„í™©60_85ì´í•˜', 'k_85_135ì´í•˜', 'k_135ì´ˆê³¼', 'ì„¸ëŒ€ì „ê¸°ê³„ì•½ë°©ë²•', 'ì£¼ì°¨ëŒ€ìˆ˜',\n",
        "       'ê´€ë¦¬ë¹„_ì—…ë¡œë“œ', 'ë¶„ì–‘ì„¸ëŒ€ìˆ˜', 'ì„ëŒ€ì„¸ëŒ€ìˆ˜',\n",
        "       'ì¼ë°˜ê´€ë¦¬-ì¸ì›', 'ê²½ë¹„ê´€ë¦¬-ì¸ì›', 'ì²­ì†Œê´€ë¦¬-ì¸ì›', 'ì „ê¸°-ìˆ˜ì „ìš©ëŸ‰', 'ìŠ¹ê°•ê¸°', 'ì§€ìƒì£¼ì°¨ëŒ€ìˆ˜', 'ì§€í•˜ì£¼ì°¨ëŒ€ìˆ˜',\n",
        "       'CCTVëŒ€ìˆ˜', 'ìµœê³ ì¸µìˆ˜', 'ì§€í•˜ì¸µìˆ˜', 'ì°¨ëŸ‰ë³´ìœ ëŒ€ìˆ˜(ì „ì²´)', 'ì°¨ëŸ‰ë³´ìœ ëŒ€ìˆ˜(ì „ê¸°ì°¨)', 'ê³„ì•½ë…„ì›”ì¼', \n",
        "       'í’€ì•„íŒŒíŠ¸ëª…', 'ì£¼ì†Œ',  'êµ¬ìˆœìœ„', 'ë™ìˆœìœ„', 'ì•„íŒŒíŠ¸ìˆœìœ„', '3ì›”í‰ë‹¨ê°€_std',\n",
        "       '3ì›”í‰ë‹¨ê°€_skew', '3ì›”í‰ë‹¨ê°€_kurt', 'ì‹ ì¶•ì—¬ë¶€', 'ì„¸ëŒ€ë‹¹ì£¼ì°¨ëŒ€ìˆ˜', 'ì„¸ëŒ€ë‹¹ìŠ¹ê°•ê¸°ëŒ€ìˆ˜',\n",
        "       'ê³ ì¸µë„', 'ë™ì„¸ëŒ€ìˆ˜', 'ì›”ê±°ë˜ê±´ìˆ˜_mean', 'ì›”ê±°ë˜ê±´ìˆ˜_std', 'ì›”ê±°ë˜ê±´ìˆ˜_skew', 'ì›”ê±°ë˜ê±´ìˆ˜_kurt',\n",
        "       'ì•„íŒŒíŠ¸ê±°ë˜íšŸìˆ˜5', 'ì „ìš©ë©´ì _mean', 'ì „ìš©ë©´ì _std', 'ì „ìš©ë©´ì _kurt', 'ì „ìš©ë©´ì _size',\n",
        "       'ì „ìš©ë©´ì ë²”ì£¼_0', 'ì „ìš©ë©´ì ë²”ì£¼_1', 'ì „ìš©ë©´ì ë²”ì£¼_2', 'ì „ìš©ë©´ì ë²”ì£¼_3', 'ì „ìš©ë©´ì ë²”ì£¼_4', 'ë²”ì£¼4ë¹„ìœ¨',\n",
        "       'ì´ì „ê³„ì•½_diff', ]\n",
        "dt_full.drop(drop_cols4,axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_full.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-2-4. Train,Test ë¶„ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_train = dt_full[dt_full['is_test']==0]\n",
        "dt_test = dt_full[dt_full['is_test']==1]\n",
        "dt_test['target'] = 0\n",
        "\n",
        "dt_train.drop(['is_test'], axis = 1, inplace=True)\n",
        "dt_test.drop(['is_test'], axis = 1, inplace=True)\n",
        "print(dt_train.shape, dt_test.shape)\n",
        "assert dt_train.shape[1] == dt_test.shape[1] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-2-5. ë²”ì£¼í˜• ë³€ìˆ˜ ì„ íƒ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cols,cat_cols,rest = [],[],[]\n",
        "\n",
        "for column in dt_train.columns:\n",
        "    if pd.api.types.is_numeric_dtype(dt_train[column]): num_cols.append(column) # \n",
        "    elif pd.api.types.is_object_dtype(dt_train[column]): cat_cols.append(column)\n",
        "    else: rest.append(column)\n",
        "    \n",
        "print(\"ì—°ì†í˜• ë³€ìˆ˜:\", num_cols)\n",
        "print(\"ë²”ì£¼í˜• ë³€ìˆ˜:\", cat_cols)\n",
        "print(\"ë‚˜ë¨¸ì§€ ë³€ìˆ˜:\", rest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-2-6. Catboost ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def objective(trial, X, y):\n",
        "\n",
        "    cbrm_param = {\n",
        "        'iterations':trial.suggest_int(\"iterations\", 400, 1200),\n",
        "        'od_wait':trial.suggest_int('od_wait', 500, 2300),\n",
        "        'learning_rate' : trial.suggest_uniform('learning_rate',0.01, 1),\n",
        "        'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n",
        "        'random_strength': trial.suggest_uniform('random_strength',10,50),\n",
        "        'depth': trial.suggest_int('depth',3, 7),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),\n",
        "        'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,15),\n",
        "        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
        "    }\n",
        "    model = CatBoostRegressor(**cbrm_param,random_state=624,task_type=\"GPU\")\n",
        "\n",
        "    folds = KFold(n_splits=5, random_state=624, shuffle=True)\n",
        "    losses = []\n",
        "\n",
        "    for train_idx, valid_idx in folds.split(X, y):\n",
        "        X_train = X.iloc[train_idx, :]\n",
        "        y_train = y.iloc[train_idx]\n",
        "\n",
        "        X_valid = X.iloc[valid_idx, :]\n",
        "        y_valid = y.iloc[valid_idx]\n",
        "\n",
        "        model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds=25,cat_features=cat_cols)\n",
        "        preds = model.predict(X_valid)\n",
        "        loss = np.sqrt(mean_squared_error(y_valid, preds))\n",
        "        losses.append(loss)\n",
        "        \n",
        "    return np.mean(losses)\n",
        "\n",
        "def make_tune_model(train_data):\n",
        "    opt_func = partial(objective, X=train_data[0], y=train_data[1]) \n",
        "    K = 5 \n",
        "    sampler = TPESampler(seed=624)\n",
        "    \n",
        "    study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
        "\n",
        "    study.optimize(opt_func, n_trials=30)\n",
        "    \n",
        "    print(\"Tuned train Score: %.4f\" % study.best_value) # best score ì¶œë ¥\n",
        "    print(\"Tuned params: \", study.best_trial.params) # best scoreì¼ ë•Œì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤\n",
        "    \n",
        "    best_params = study.best_params\n",
        "    best_model = CatBoostRegressor(**best_params,random_state=624,task_type=\"GPU\")\n",
        "    best_model.fit(train_data[0], train_data[1],cat_features=cat_cols)\n",
        "    \n",
        "    return best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4-2-6-1. ì „ì²´ í•™ìŠµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path=\"../model\"\n",
        "\n",
        "X_train=dt_train.drop(['target'], axis=1)\n",
        "y_train=dt_train['target']\n",
        "#model=make_tune_model([X_train,y_train])\n",
        "#save_model('Total',model)\n",
        "model=load_model('Total')\n",
        "best_params = model.get_params()\n",
        "model = CatBoostRegressor(**best_params)\n",
        "model.fit(X_train, y_train,cat_features=cat_cols)\n",
        "save_model('Total',model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model=load_model('Total')\n",
        "importances = pd.Series(model.feature_importances_, index=list(X_train.columns))\n",
        "importances = importances.sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.title(\"Feature Importances\")\n",
        "sns.barplot(x=importances, y=importances.index)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred=model.predict(X_train)\n",
        "y_pred,y_train=transform_log(y_pred,y_train)\n",
        "result=pd.DataFrame({'pred': y_pred, 'target': y_train})\n",
        "\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.plot(result.index, result['target'], label='Target')\n",
        "plt.plot(result.index, result['pred'], label='Predictions', marker='x')\n",
        "plt.title(f'Train Result by Total')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Values')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4-2-6-2. êµ¬ë³„ í•™ìŠµ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path=\"../model/êµ¬ë³„\"\n",
        "gu_col=dt_train['êµ¬'].unique()\n",
        "model_list=[]\n",
        "\n",
        "for gu in gu_col:\n",
        "    tmp_train=dt_train[dt_train['êµ¬']==gu]\n",
        "    X_train=tmp_train.drop(['target'], axis=1)\n",
        "    y_train=tmp_train['target']\n",
        "    \n",
        "    # model=make_tune_model([X_train,y_train])\n",
        "    # save_model(f'{gu}',model)\n",
        "    model=load_model(f'Catboost_{gu}')\n",
        "    best_params = model.get_params()\n",
        "    model = CatBoostRegressor(**best_params)\n",
        "    model.fit(X_train, y_train,cat_features=cat_cols)\n",
        "    save_model(f'Catboost_{gu}',model)\n",
        "    \n",
        "    model_list.append(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "VbgCRxFgdFQb",
        "outputId": "f9114f72-78e1-471c-fc0b-ba5b8b6b6d2f"
      },
      "outputs": [],
      "source": [
        "for gu in gu_col:\n",
        "    model=load_model(f\"Catboost_{gu}\")\n",
        "    importances = pd.Series(model.feature_importances_, index=list(X_train.columns))\n",
        "    importances = importances.sort_values(ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.title(f\"{gu} Feature Importances\")\n",
        "    sns.barplot(x=importances, y=importances.index)\n",
        "    plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "answer=[]\n",
        "for gu in gu_col:\n",
        "    tmp_train=dt_train[dt_train['êµ¬']==gu]\n",
        "    X_train=tmp_train.drop(['target'], axis=1)\n",
        "    y_train=tmp_train['target']\n",
        "    \n",
        "    idx=X_train.index.copy()\n",
        "    model=load_model(f'Catboost_{gu}')\n",
        "    \n",
        "    gu_pred = model.predict(X_train)\n",
        "    \n",
        "    gu_pred,y_train=transform_log(gu_pred,y_train)\n",
        "    gu_pred=pd.DataFrame({'pred': gu_pred, 'target': y_train})\n",
        "    gu_pred['idx']=idx\n",
        "    answer.append(gu_pred)\n",
        "    \n",
        "gu_result = pd.concat(answer)\n",
        "gu_result = gu_result.sort_values(by='idx')\n",
        "gu_result.drop(['idx'],axis=1,inplace=True)\n",
        "gu_result.reset_index(drop=True,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 6))\n",
        "plt.plot(gu_result.index, gu_result['target'], label='Target')\n",
        "plt.plot(gu_result.index, gu_result['pred'], label='Predictions', marker='x')\n",
        "plt.title(f'Train Result by GU')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Values')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4-2-6-3.ë©´ì ë³„ í•™ìŠµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path=\"../model/ë©´ì ë³„\"\n",
        "size_col=dt_train['ì „ìš©ë©´ì ë²”ì£¼'].unique()\n",
        "model_list=[]\n",
        "\n",
        "for size in size_col:\n",
        "    tmp_train=dt_train[dt_train['ì „ìš©ë©´ì ë²”ì£¼']==size]\n",
        "    X_train=tmp_train.drop(['target'], axis=1)\n",
        "    y_train=tmp_train['target']\n",
        "    \n",
        "    # model=make_tune_model([X_train,y_train])\n",
        "    # save_model(f'size_{size}',model)\n",
        "    \n",
        "    model=load_model(f'Catboost{size}')\n",
        "    best_params = model.get_params()\n",
        "    model = CatBoostRegressor(**best_params)\n",
        "    model.fit(X_train, y_train,cat_features=cat_cols)\n",
        "    save_model(f'Catboost_{size}',model)\n",
        "    \n",
        "    model_list.append(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for size in size_col:\n",
        "    model=load_model(f'Catboost_{size}')\n",
        "    importances = pd.Series(model.feature_importances_, index=list(X_train.columns))\n",
        "    importances = importances.sort_values(ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.title(f\"{size} Feature Importances\")\n",
        "    sns.barplot(x=importances, y=importances.index)\n",
        "    plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_list=[]\n",
        "\n",
        "answer=[]\n",
        "for size in size_col:\n",
        "    tmp_train=dt_train[dt_train['ì „ìš©ë©´ì ë²”ì£¼']==size]\n",
        "    X_train=tmp_train.drop(['target'], axis=1)\n",
        "    y_train=tmp_train['target']\n",
        "    \n",
        "    idx=X_train.index.copy()\n",
        "    model=load_model(f'Catboost_{size}')\n",
        "    \n",
        "    size_pred = model.predict(X_train)\n",
        "    size_pred,y_train=transform_log(size_pred,y_train)\n",
        "    \n",
        "    size_pred=pd.DataFrame({'pred': size_pred, 'target': y_train})\n",
        "    size_pred['idx']=idx\n",
        "    answer.append(size_pred)\n",
        "    \n",
        "size_result = pd.concat(answer)\n",
        "size_result = size_result.sort_values(by='idx')\n",
        "size_result.drop(['idx'],axis=1,inplace=True)\n",
        "size_result.reset_index(drop=True,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 6))\n",
        "plt.plot(size_result.index, size_result['target'], label='Target')\n",
        "plt.plot(size_result.index, size_result['pred'], label='Predictions', marker='x')\n",
        "plt.title(f'Train Result by SIZE')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Values')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-2-7. Catboost ëª¨ë¸ ì¶”ë¡ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4-2-7-1. ì „ì²´ ì¶”ë¡ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path=\"../model\"\n",
        "model=load_model(\"Total\")\n",
        "X_test = dt_test.drop(['target'], axis=1)\n",
        "total_pred = model.predict(X_test)\n",
        "total_pred,_=transform_log(total_pred,0)\n",
        "total_result = pd.DataFrame(total_pred.astype(int), columns=[\"target\"])\n",
        "total_result.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rmse = np.sqrt(mean_squared_error(y_test, total_result['target']))\n",
        "\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.text(0.5, 0.9, f'RMSE: {rmse:.2f}', fontsize=20, ha='center', transform=plt.gca().transAxes)\n",
        "plt.plot(total_result.index,y_test, label='Target')\n",
        "plt.plot(total_result.index, total_result['target'], label='Pred')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Values')\n",
        "plt.legend()\n",
        "plt.ylim(0, 1800000)\n",
        "plt.yticks([i for i in range(0, 1800001, 250000)])\n",
        "plt.title(\"Test set Predict by TOTAL\")\n",
        "plt.grid(True)\n",
        "plt.show();\n",
        "#total_result.to_csv(f'{submission_path}/20240123_Cat_optuna_total.csv', index=False);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4-2-7-2. êµ¬ë³„ ì¶”ë¡ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path=\"../model/êµ¬ë³„\"\n",
        "gu_col=dt_train['êµ¬'].unique()\n",
        "model_list=[]\n",
        "\n",
        "answer=[]\n",
        "for gu in gu_col:\n",
        "    tmp_test=dt_test[dt_test['êµ¬']==gu]\n",
        "    X_test=tmp_test.drop(['target'], axis=1)\n",
        "    \n",
        "    idx=X_test.index.copy()\n",
        "    model=load_model(f\"Catboost_{gu}\")\n",
        "\n",
        "    gu_pred = model.predict(X_test)\n",
        "    gu_pred,_=transform_log(gu_pred,0)\n",
        "    \n",
        "    gu_pred=pd.DataFrame({'target': gu_pred.astype(int)})\n",
        "    gu_pred['idx']=idx\n",
        "    answer.append(gu_pred)\n",
        "    \n",
        "gu_result = pd.concat(answer)\n",
        "gu_result = gu_result.sort_values(by='idx')\n",
        "gu_result.drop(['idx'],axis=1,inplace=True)\n",
        "gu_result.reset_index(drop=True,inplace=True)\n",
        "gu_result.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rmse = np.sqrt(mean_squared_error(y_test, gu_result['target']))\n",
        "\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.text(0.5, 0.9, f'RMSE: {rmse:.2f}', fontsize=20, ha='center', transform=plt.gca().transAxes)\n",
        "plt.plot(gu_result.index,y_test, label='Target')\n",
        "plt.plot(gu_result.index, gu_result['target'], label='Pred')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Values')\n",
        "plt.legend()\n",
        "plt.ylim(0, 1800000)\n",
        "plt.yticks([i for i in range(0, 1800001, 250000)])\n",
        "plt.title(\"Test set Predict by Gu\")\n",
        "plt.grid(True)\n",
        "plt.show();\n",
        "#gu_result.to_csv(f'{submission_path}/20240123_Cat_optuna_gu.csv', index=False);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4-2-7-3. ë©´ì ë³„ ì¶”ë¡ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path=\"../model/ë©´ì ë³„\"\n",
        "size_col=dt_train['ì „ìš©ë©´ì ë²”ì£¼'].unique()\n",
        "model_list=[]\n",
        "\n",
        "answer=[]\n",
        "for size in size_col:\n",
        "    tmp_test=dt_test[dt_test['ì „ìš©ë©´ì ë²”ì£¼']==size]\n",
        "    X_test=tmp_test.drop(['target'], axis=1)\n",
        "\n",
        "    idx=X_test.index.copy()\n",
        "    model=load_model(f\"Catboost_{size}\")\n",
        "    \n",
        "    size_pred = model.predict(X_test)\n",
        "    size_pred,_=transform_log(size_pred,0)\n",
        "\n",
        "    size_pred=pd.DataFrame({'target': size_pred.astype(int)})\n",
        "    size_pred['idx']=idx\n",
        "    answer.append(size_pred)\n",
        "    \n",
        "size_result = pd.concat(answer)\n",
        "size_result = size_result.sort_values(by='idx')\n",
        "size_result.drop(['idx'],axis=1,inplace=True)\n",
        "size_result.reset_index(drop=True,inplace=True)\n",
        "size_result.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rmse = np.sqrt(mean_squared_error(y_test, size_result['target']))\n",
        "\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.text(0.5, 0.9, f'RMSE: {rmse:.2f}', fontsize=20, ha='center', transform=plt.gca().transAxes)\n",
        "plt.plot(size_result.index,y_test, label='Target')\n",
        "plt.plot(size_result.index, size_result['target'], label='Pred')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Values')\n",
        "plt.legend()\n",
        "plt.ylim(0, 1800000)\n",
        "plt.yticks([i for i in range(0, 1800001, 250000)])\n",
        "plt.title(\"Test set Predict by SIZE\")\n",
        "plt.grid(True)\n",
        "plt.show();\n",
        "#size_result.to_csv(f'{submission_path}/20240123_Cat_optuna_size.csv', index=False);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 6))\n",
        "plt.plot(adjust_result.index, adjust_result['target'], label='Target')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Values')\n",
        "plt.ylim(0, 1800000)\n",
        "plt.yticks([i for i in range(0, 1800001, 250000)])\n",
        "plt.legend()\n",
        "plt.title(\"Test set Predict*Weight\")\n",
        "plt.grid(True)\n",
        "plt.show();\n",
        "#adjust_result.to_csv(f'{submission_path}/20240121_cat_by gu_recent+adjust.csv', index=False);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ê°€ì¤‘ì¹˜ ì¡°ì ˆ sizeë³„ ëª¨ë¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_test_tmp=dt_test.copy()\n",
        "\n",
        "model_path=\"../model\"\n",
        "dt_train.columns\n",
        "model=load_model(\"Total\")\n",
        "X_test = dt_test_tmp.drop(['target'], axis=1)\n",
        "size_tmp=X_test['ì „ìš©ë©´ì ë²”ì£¼'].values\n",
        "total_pred = model.predict(X_test)\n",
        "total_pred  = np.expm1(total_pred )\n",
        "total_result = pd.DataFrame(total_pred.astype(int), columns=[\"target\"])\n",
        "#total_result['ì „ìš©ë©´ì ë²”ì£¼']=size_tmp\n",
        "#total_result['real_target']=test_target\n",
        "total_result.head(3)\n",
        "#total_result=total_result.sort_values(by='ì „ìš©ë©´ì ë²”ì£¼',ignore_index=True)\n",
        "\n",
        "\n",
        "total_result.loc[total_result['target'] > 0, 'target'] *= 1.1\n",
        "#rmse = np.sqrt(mean_squared_error(total_result['real_target'], total_result['target']))\n",
        "\n",
        "plt.figure(figsize=(20, 6))\n",
        "#plt.text(0.5, 0.9, f'RMSE: {rmse:.2f}', fontsize=20, ha='center', transform=plt.gca().transAxes)\n",
        "#plt.plot(total_result.index,total_result['real_target'], label='Target')\n",
        "plt.plot(total_result.index, total_result['target'], label='Pred')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Values')\n",
        "plt.legend()\n",
        "plt.ylim(0, 1800000)\n",
        "plt.yticks([i for i in range(0, 1800001, 250000)])\n",
        "plt.title(\"Test set Predict by total\")\n",
        "plt.grid(True)\n",
        "plt.show();\n",
        "#size_result.to_csv(f'{submission_path}/20240123_Cat_optuna_size.csv', index=False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_result['target']=total_result['target'].astype('int')\n",
        "total_result.to_csv(f'{submission_path}/20240123_Cat_optuna_total_1_1.csv', index=False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "our=pd.read_csv(\"../submission/20240123_Cat_optuna_total_1_1.csv\")\n",
        "hyo=pd.read_csv(\"sub.csv\")\n",
        "base=pd.read_csv(\"baseline.csv.csv\")\n",
        "yc=pd.read_csv(\"youngcheon.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 6))\n",
        "#plt.plot(our.index, our['target'], label='our')\n",
        "#plt.plot(hyo.index, hyo['target'], label='hyo')\n",
        "plt.plot(yc.index, yc['target'], label='yc')\n",
        "plt.plot(our.index, our['target'], label='our')\n",
        "plt.title('Real Target')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Values')\n",
        "plt.ylim(0, 1800000)\n",
        "plt.yticks([i for i in range(0, 1800001, 250000)])\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RMSE = mean_squared_error(our['target'], hyo['target'])**0.5\n",
        "RMSE"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
